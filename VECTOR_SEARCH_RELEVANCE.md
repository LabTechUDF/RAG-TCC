# ğŸ¯ Sistema de RelevÃ¢ncia Vetorial - DocumentaÃ§Ã£o TÃ©cnica

## ğŸ“‹ Ãndice

1. [VisÃ£o Geral](#visÃ£o-geral)
2. [Arquitetura do Sistema](#arquitetura-do-sistema)
3. [Score de RelevÃ¢ncia](#score-de-relevÃ¢ncia)
4. [Fluxo de Dados Completo](#fluxo-de-dados-completo)
5. [ImplementaÃ§Ã£o TÃ©cnica](#implementaÃ§Ã£o-tÃ©cnica)
6. [Metadados JurÃ­dicos](#metadados-jurÃ­dicos)
7. [InterpretaÃ§Ã£o de Resultados](#interpretaÃ§Ã£o-de-resultados)
8. [OtimizaÃ§Ãµes e Performance](#otimizaÃ§Ãµes-e-performance)
9. [Troubleshooting](#troubleshooting)

---

## ğŸŒŸ VisÃ£o Geral

O sistema de relevÃ¢ncia vetorial Ã© o **coraÃ§Ã£o da busca semÃ¢ntica** no RAG JurÃ­dico. Ele transforma consultas em linguagem natural em vetores matemÃ¡ticos e encontra documentos juridicamente relevantes atravÃ©s de **similaridade semÃ¢ntica**, nÃ£o apenas por palavras-chave.

### Componentes Principais

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Query Texto   â”‚
â”‚ "art. 319 CPP"  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Embedding     â”‚â”€â”€â”€â”€â”€â”€â–¶â”‚  FAISS Index     â”‚
â”‚  Model (768D)   â”‚      â”‚  (Vetores L2)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â†“
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚ Top-K Docs +   â”‚
                         â”‚ Scores (0-1)   â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Tecnologias Utilizadas

- **Modelo de Embeddings**: `sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2`
- **Dimensionalidade**: 768 dimensÃµes
- **Biblioteca de Busca**: FAISS (Facebook AI Similarity Search)
- **MÃ©trica de Similaridade**: Produto Interno (Inner Product) â‰ˆ Cosseno
- **Backend API**: FastAPI (Python 3.12+)
- **Frontend**: Nuxt 3 + TypeScript

---

## ğŸ—ï¸ Arquitetura do Sistema

### Camadas da AplicaÃ§Ã£o

#### **1. Frontend (Interface Nuxt 3)**
```typescript
// Interface/app/composables/useVectorSearch.ts
interface SearchDocument {
  id: string
  title?: string
  text: string
  court?: string
  code?: string
  article?: string
  date?: string
  case_number?: string  // NÃºmero do processo
  relator?: string      // Ministro relator
  source?: string       // Tribunal (STF, STJ, etc)
  meta?: Record<string, any>
  score: number         // â­ Score de relevÃ¢ncia (0-1)
}
```

#### **2. Backend (DBVECTOR API - FastAPI)**
```python
# DBVECTOR/src/api/main.py
class SearchResultAPI(BaseModel):
    id: str
    title: Optional[str] = None
    text: str
    court: Optional[str] = None
    code: Optional[str] = None
    article: Optional[str] = None
    date: Optional[str] = None
    case_number: Optional[str] = None
    relator: Optional[str] = None
    source: Optional[str] = None
    meta: Optional[dict] = None
    score: float  # â­ Score de relevÃ¢ncia
```

#### **3. Storage Layer (FAISS Store)**
```python
# DBVECTOR/src/storage/faiss_store.py
class FAISSStore(VectorStore):
    def search(self, query_vector, k=5) -> List[SearchResult]:
        # Busca vetorial + score de similaridade
        scores, internal_ids = self._index.search(query_vector, k)
        # scores: array([0.856, 0.782, 0.654, ...])
```

---

## ğŸ“Š Score de RelevÃ¢ncia

### O que Ã© o Score?

O **score de relevÃ¢ncia** Ã© um valor numÃ©rico entre **-1 e 1** (na prÃ¡tica, **0 a 1** para textos similares) que representa o **quÃ£o semanticamente prÃ³ximo** um documento estÃ¡ da consulta do usuÃ¡rio.

### Como Ã© Calculado?

#### **Passo 1: VetorizaÃ§Ã£o (Embeddings)**

Tanto a query quanto os documentos sÃ£o transformados em vetores de 768 dimensÃµes:

```python
# Query do usuÃ¡rio
query = "Explique medidas cautelares art. 319 CPP"

# VetorizaÃ§Ã£o usando sentence-transformers
query_vector = encoder.encode(query)
# Resultado: numpy.array([0.123, -0.456, 0.789, ..., 0.321])
#           shape=(768,)

# Documento no banco
doc_text = "Art. 319. SÃ£o medidas cautelares diversas da prisÃ£o..."
doc_vector = encoder.encode(doc_text)
# Resultado: numpy.array([0.145, -0.423, 0.801, ..., 0.298])
#           shape=(768,)
```

#### **Passo 2: Produto Interno (Dot Product)**

O FAISS calcula o **produto interno** entre os vetores:

```python
score = np.dot(query_vector, doc_vector)

# Matematicamente:
# score = Î£(query[i] Ã— doc[i]) para i âˆˆ [0, 767]
# score = query[0]Ã—doc[0] + query[1]Ã—doc[1] + ... + query[767]Ã—doc[767]
```

#### **Passo 3: NormalizaÃ§Ã£o (ImplÃ­cita)**

Como os embeddings do `sentence-transformers` sÃ£o **normalizados L2** (norma euclidiana = 1), o produto interno equivale Ã  **similaridade de cosseno**:

```python
# Para vetores normalizados ||v|| = 1:
cosine_similarity(a, b) = dot_product(a, b)

# Geometricamente:
# cos(Î¸) onde Î¸ Ã© o Ã¢ngulo entre os vetores
# cos(0Â°) = 1.0  â†’ Vetores idÃªnticos
# cos(45Â°) = 0.7 â†’ Vetores similares
# cos(90Â°) = 0.0 â†’ Vetores ortogonais (sem relaÃ§Ã£o)
```

### FÃ³rmula Completa

```
Score = dot_product(query_embedding, doc_embedding)
      = Î£(q[i] Ã— d[i])  para i âˆˆ [0, 767]
      = ||q|| Ã— ||d|| Ã— cos(Î¸)
      = 1 Ã— 1 Ã— cos(Î¸)    (vetores normalizados)
      = cos(Î¸)
      âˆˆ [-1, 1]           (teoricamente)
      âˆˆ [0, 1]            (na prÃ¡tica para textos em portuguÃªs)
```

### ConfiguraÃ§Ã£o no FAISS

```python
# DBVECTOR/src/storage/faiss_store.py
# IndexFlatIP = Index Flat Inner Product
base_index = faiss.IndexFlatIP(dimension=768)

# Equivalente a:
# - Busca exaustiva (Flat) sem compressÃ£o
# - MÃ©trica de similaridade: Produto Interno (IP)
# - Sem quantizaÃ§Ã£o ou clustering
```

---

## ğŸ”„ Fluxo de Dados Completo

### Fluxo End-to-End

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. USUÃRIO DIGITA QUERY                                  â”‚
â”‚    "Explique medidas cautelares art. 319"                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. FRONTEND (useVectorSearch.ts)                         â”‚
â”‚    - Valida query (min 2 chars)                          â”‚
â”‚    - Chama G1 Query Builder (opcional)                   â”‚
â”‚    - Otimiza: "prisÃ£o preventiva art. 319 requisitos"    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ HTTP POST /search
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. BACKEND API (main.py)                                 â”‚
â”‚    POST /search { q: "...", k: 5 }                       â”‚
â”‚    - Valida request                                      â”‚
â”‚    - Gera embedding da query (768D)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ embeddings.encode_single_text()
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. EMBEDDING MODEL                                       â”‚
â”‚    paraphrase-multilingual-MiniLM-L12-v2                 â”‚
â”‚    Input:  "prisÃ£o preventiva art. 319 requisitos"       â”‚
â”‚    Output: array([0.123, -0.456, ..., 0.789])            â”‚
â”‚            shape=(768,)                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ query_vector
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. FAISS STORE (faiss_store.py)                          â”‚
â”‚    store.search(query_vector, k=5)                       â”‚
â”‚    - Carrega Ã­ndice FAISS                                â”‚
â”‚    - Busca top-k vetores mais prÃ³ximos                   â”‚
â”‚    - Calcula scores (produto interno)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ scores, internal_ids
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. RECONSTRUÃ‡ÃƒO DE DOCUMENTOS                            â”‚
â”‚    Para cada internal_id:                                â”‚
â”‚    - Recupera metadata[internal_id]                      â”‚
â”‚    - Extrai: id, title, text, case_number, relator, etc  â”‚
â”‚    - Cria Doc + SearchResult(doc, score)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ List[SearchResult]
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 7. BACKEND RESPONSE                                      â”‚
â”‚    SearchResponseAPI {                                   â”‚
â”‚      query: "...",                                       â”‚
â”‚      total: 5,                                           â”‚
â”‚      backend: "faiss",                                   â”‚
â”‚      results: [                                          â”‚
â”‚        { id: "HC_187657", score: 0.856, ... },           â”‚
â”‚        { id: "HC_169805", score: 0.782, ... },           â”‚
â”‚        ...                                               â”‚
â”‚      ]                                                   â”‚
â”‚    }                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ JSON Response
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 8. FRONTEND PROCESSING                                   â”‚
â”‚    vectorResults.value = searchResponse.results          â”‚
â”‚    - Ordena por score (maior â†’ menor)                    â”‚
â”‚    - Exibe documentos relevantes                         â”‚
â”‚    - Calcula avg_score, top_score                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 9. G2 ANSWER COMPOSER                                    â”‚
â”‚    - Usa top-k documentos como contexto                  â”‚
â”‚    - Gera resposta fundamentada                          â”‚
â”‚    - Cita fontes: [HC_187657]                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 10. ENRIQUECIMENTO DE CITAÃ‡Ã•ES (enrichedCitations)       â”‚
â”‚     - Mapeia citation IDs â†’ documentos completos         â”‚
â”‚     - Extrai: case_number, relator, source, score        â”‚
â”‚     - Exibe em cards visuais                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Exemplo Real com Dados

#### **Input**
```typescript
query: "Explique medidas cautelares art. 319"
k: 5
```

#### **Embedding Gerado**
```python
query_vector: array([
  0.0234, -0.1234,  0.4567, -0.0789,  0.2345,
  0.1111, -0.3333,  0.5555, -0.2222,  0.4444,
  ...  # 768 dimensÃµes total
  0.0987, -0.2345,  0.6789, -0.1234,  0.3456
])
```

#### **FAISS Search**
```python
scores, ids = index.search(query_vector, k=5)

scores: array([0.856, 0.782, 0.654, 0.589, 0.512])
ids:    array([42315, 89234, 12456, 56789, 23451])
```

#### **Documentos Retornados**
```json
{
  "query": "Explique medidas cautelares art. 319",
  "total": 5,
  "backend": "faiss",
  "results": [
    {
      "id": "HC_187657",
      "title": "HC 187657 / GO - GOIÃS",
      "score": 0.856,
      "case_number": "0096679-75.2020.1.00.0000",
      "relator": "CÃRMEN LÃšCIA",
      "source": "STF - art_244",
      "date": "05/08/2020",
      "text": "...prisÃ£o preventiva art. 319 medidas cautelares..."
    },
    {
      "id": "HC_169805",
      "title": "HC 169805 / PR - PARANÃ",
      "score": 0.782,
      "case_number": "0020283-91.2019.1.00.0000",
      "relator": "CELSO DE MELLO",
      "source": "STF - art_244",
      "date": "07/10/2020",
      "text": "...cÃ³digo penal militar art. 290 prisÃ£o preventiva..."
    }
    // ... mais 3 documentos
  ]
}
```

---

## ğŸ’» ImplementaÃ§Ã£o TÃ©cnica

### Backend: IndexaÃ§Ã£o de Documentos

```python
# DBVECTOR/src/storage/faiss_store.py

def index(self, docs: List[Doc]) -> None:
    """Indexa documentos no FAISS."""
    
    # 1. Gera embeddings para todos os textos
    texts = [doc.text for doc in docs]
    vectors = embeddings.encode_texts(texts)  # shape=(N, 768)
    
    # 2. Cria Ã­ndice FAISS
    if self._index is None:
        dimension = vectors.shape[1]  # 768
        base_index = faiss.IndexFlatIP(dimension)  # Inner Product
        self._index = faiss.IndexIDMap2(base_index)  # Com IDs customizados
    
    # 3. Armazena metadados (incluindo campos jurÃ­dicos)
    internal_ids = []
    for doc in docs:
        internal_id = self._doc_to_internal_id(doc.id)  # Hash do ID
        internal_ids.append(internal_id)
        
        meta = doc.meta or {}
        self.metadata[internal_id] = {
            'id': doc.id,
            'title': doc.title,
            'text': doc.text,
            'court': doc.court,
            'code': doc.code,
            'article': doc.article,
            'date': doc.date,
            'case_number': meta.get('case_number'),  # â­ Metadado jurÃ­dico
            'relator': meta.get('relator'),          # â­ Metadado jurÃ­dico
            'source': meta.get('source'),            # â­ Metadado jurÃ­dico
            'meta': doc.meta
        }
    
    # 4. Adiciona vetores ao Ã­ndice
    self._index.add_with_ids(
        vectors, 
        np.array(internal_ids, dtype=np.int64)
    )
    
    # 5. Persiste no disco
    self._save_index()
```

### Backend: Busca de Documentos

```python
def search(self, query_vector: np.ndarray, k: int = 5) -> List[SearchResult]:
    """Busca documentos similares."""
    
    # 1. Garante formato 2D: (1, 768)
    if query_vector.ndim == 1:
        query_vector = query_vector.reshape(1, -1)
    
    # 2. Busca no FAISS (retorna scores e IDs)
    scores, internal_ids = self._index.search(query_vector, k)
    
    # 3. ReconstrÃ³i documentos a partir dos metadados
    results = []
    for score, internal_id in zip(scores[0], internal_ids[0]):
        if internal_id == -1:  # ID invÃ¡lido (nÃ£o encontrado)
            continue
        
        if internal_id in self.metadata:
            doc_data = self.metadata[internal_id]
            
            # Cria objeto Doc
            doc = Doc(
                id=doc_data['id'],
                text=doc_data['text'],
                title=doc_data['title'],
                court=doc_data['court'],
                code=doc_data['code'],
                article=doc_data['article'],
                date=doc_data['date'],
                meta=doc_data['meta']
            )
            
            # Garante que metadados jurÃ­dicos estÃ£o no meta
            if not doc.meta:
                doc.meta = {}
            if 'case_number' not in doc.meta and doc_data.get('case_number'):
                doc.meta['case_number'] = doc_data['case_number']
            if 'relator' not in doc.meta and doc_data.get('relator'):
                doc.meta['relator'] = doc_data['relator']
            if 'source' not in doc.meta and doc_data.get('source'):
                doc.meta['source'] = doc_data['source']
            
            # Adiciona resultado com score
            results.append(SearchResult(doc=doc, score=float(score)))
    
    return results
```

### Backend: API Endpoint

```python
# DBVECTOR/src/api/main.py

@app.post("/search", response_model=SearchResponseAPI)
async def search_documents(request: SearchRequest):
    """Busca documentos jurÃ­dicos por similaridade semÃ¢ntica."""
    
    # 1. Gera embedding da query
    query_vector = embeddings.encode_single_text(request.q)
    
    # 2. Busca no store
    results = store.search(query_vector, k=request.k)
    
    # 3. Converte para modelo API (extrai metadados do meta)
    api_results = []
    for result in results:
        doc = result.doc
        meta = doc.meta or {}
        
        api_result = SearchResultAPI(
            id=doc.id,
            title=doc.title,
            text=doc.text,
            court=doc.court,
            code=doc.code,
            article=doc.article,
            date=doc.date,
            case_number=meta.get('case_number'),  # â­ Extrai do meta
            relator=meta.get('relator'),          # â­ Extrai do meta
            source=meta.get('source'),            # â­ Extrai do meta
            meta=doc.meta,
            score=result.score  # â­ Score de relevÃ¢ncia
        )
        api_results.append(api_result)
    
    return SearchResponseAPI(
        query=request.q,
        total=len(api_results),
        backend=config.SEARCH_BACKEND,
        results=api_results
    )
```

### Frontend: Busca Vetorial

```typescript
// Interface/app/composables/useVectorSearch.ts

async function search(
  query: string,
  options: SearchOptions = {}
): Promise<SearchResponse> {
  
  const { k = 5, optimize = true } = options
  
  // 1. Otimiza query com G1 Query Builder (opcional)
  let finalQuery = query
  if (optimize) {
    const optimized = await optimizeQuery({ user_query: query })
    finalQuery = optimized.optimized_query
  }
  
  // 2. Chama API DBVECTOR
  const dbvectorUrl = config.public.dbvectorApiUrl || 'http://localhost:8000'
  const response = await $fetch<SearchResponse>(`${dbvectorUrl}/search`, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: { q: finalQuery, k }
  })
  
  // 3. Retorna documentos com scores
  return response
}
```

### Frontend: Enriquecimento de CitaÃ§Ãµes

```typescript
// Interface/app/pages/index.vue

// Computed property: mapeia IDs de citaÃ§Ãµes â†’ documentos completos
const enrichedCitations = computed(() => {
  if (!citations.value || citations.value.length === 0) {
    return []
  }
  
  return citations.value
    .map(citationId => {
      // Busca documento nos resultados vetoriais (case-insensitive)
      const doc = vectorResults.value.find(
        result => result.id.toLowerCase() === citationId.toLowerCase()
      )
      
      if (!doc) {
        return {
          id: citationId,
          title: 'Documento nÃ£o encontrado',
          notFound: true
        }
      }
      
      // Retorna documento enriquecido com TODOS os metadados
      return {
        id: doc.id,
        title: doc.title || 'Documento JurÃ­dico',
        case_number: doc.case_number,  // â­ NÃºmero do processo
        relator: doc.relator,          // â­ Ministro relator
        source: doc.source,            // â­ Tribunal (STF, STJ)
        date: doc.date,
        court: doc.court,
        article: doc.article,
        text: doc.text,
        score: doc.score,              // â­ RelevÃ¢ncia (0-1)
        notFound: false
      }
    })
    .filter(doc => !doc.notFound)  // Remove nÃ£o encontrados
})
```

---

## ğŸ“‘ Metadados JurÃ­dicos

### Origem dos Dados

Os metadados jurÃ­dicos sÃ£o extraÃ­dos dos arquivos **JSONL** gerados pelos scrapers (STF, STJ, TRF4):

```json
{
  "cluster_name": "art_244",
  "cluster_description": "abandono material artigo 244 (art. 244 do CÃ³digo Penal)",
  "article_reference": "CP art. 244",
  "source": "STF - art_244",
  "title": "HC 187657",
  "case_number": "despacho1123501",
  "content": "HC 187657 / GO - GOIÃS...",
  "url": "https://jurisprudencia.stf.jus.br/pages/search/despacho1123501/false",
  "tribunal": "STF",
  "legal_area": "Penal",
  "classe_processual_unificada": null,
  "relator": "CÃRMEN LÃšCIA",
  "publication_date": "05/08/2020",
  "decision_date": "27/07/2020",
  "numero_unico": "0096679-75.2020.1.00.0000"
}
```

### Mapeamento de Campos

| Campo JSONL | Campo API | DescriÃ§Ã£o | Exemplo |
|-------------|-----------|-----------|---------|
| `case_number` | `case_number` | ID do caso/despacho | `despacho1123501` |
| `relator` | `relator` | Ministro/Desembargador | `CÃRMEN LÃšCIA` |
| `source` | `source` | Tribunal + cluster | `STF - art_244` |
| `numero_unico` | `meta.numero_unico` | CNJ | `0096679-75.2020.1.00.0000` |
| `publication_date` | `date` | Data de publicaÃ§Ã£o | `05/08/2020` |
| `title` | `title` | Tipo + nÃºmero | `HC 187657` |
| `tribunal` | `court` | Tribunal | `STF` |
| `content` | `text` | Texto completo | `HC 187657 / GO - GOIÃS...` |

### Fluxo de Metadados

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Scraper (STF, STJ)  â”‚
â”‚ - Coleta decisÃµes   â”‚
â”‚ - Extrai metadados  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚ JSONL
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Tratamento de Dados â”‚
â”‚ - Limpa HTML        â”‚
â”‚ - Valida campos     â”‚
â”‚ - Remove duplicatas â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚ merged_clean.jsonl
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Pipeline de Build   â”‚
â”‚ - Cria Doc objects  â”‚
â”‚ - Gera embeddings   â”‚
â”‚ - Indexa no FAISS   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚ index.faiss + metadata.parquet
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FAISS Store         â”‚
â”‚ self.metadata = {   â”‚
â”‚   42315: {          â”‚
â”‚     'id': 'HC_...'  â”‚
â”‚     'case_number'   â”‚
â”‚     'relator'       â”‚
â”‚     'source'        â”‚
â”‚     ...             â”‚
â”‚   }                 â”‚
â”‚ }                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚ search()
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ API Response        â”‚
â”‚ SearchResultAPI {   â”‚
â”‚   case_number âœ“     â”‚
â”‚   relator âœ“         â”‚
â”‚   source âœ“          â”‚
â”‚   score âœ“           â”‚
â”‚ }                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚ HTTP JSON
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Frontend UI         â”‚
â”‚ enrichedCitations   â”‚
â”‚ - Mapeia citaÃ§Ãµes   â”‚
â”‚ - Exibe metadados   â”‚
â”‚ - Mostra score      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ˆ InterpretaÃ§Ã£o de Resultados

### Tabela de InterpretaÃ§Ã£o de Scores

| Score Range | Badge | InterpretaÃ§Ã£o | Significado PrÃ¡tico |
|-------------|-------|---------------|---------------------|
| **0.85 - 1.0** | ğŸ¯ **Alta** | Documento **altamente relevante** | Responde diretamente Ã  query; use com confianÃ§a |
| **0.70 - 0.84** | âš¡ **Boa** | Documento **relevante** | Boa correspondÃªncia semÃ¢ntica; Ãºtil para resposta |
| **0.50 - 0.69** | âš ï¸ **MÃ©dia** | Documento **relacionado** | Contexto tangencial; verificar antes de usar |
| **0.30 - 0.49** | ğŸ”¶ **Baixa** | Documento **fracamente relacionado** | Pode gerar alucinaÃ§Ãµes; evitar citar |
| **< 0.30** | âŒ **Irrelevante** | Documento **sem relaÃ§Ã£o** | NÃ£o usar; sem relevÃ¢ncia semÃ¢ntica |

### Exemplos Reais

#### **Query: "Explique medidas cautelares art. 319 CPP"**

| Documento | Score | Por que? |
|-----------|-------|----------|
| **HC 187657** (prisÃ£o preventiva art. 319) | **0.856** | âœ… Menciona explicitamente "art. 319 CPP", "medidas cautelares", "prisÃ£o preventiva" |
| **HC 169805** (posse de entorpecente militar) | **0.623** | âš ï¸ Fala de "medidas cautelares" genÃ©ricas, mas contexto diferente (direito militar) |
| **HC 123456** (abandono material art. 244) | **0.412** | âš ï¸ Tema completamente diferente, apenas conexÃ£o tangencial em "medidas" |

### AnÃ¡lise SemÃ¢ntica

#### **Alta RelevÃ¢ncia (0.856)**
```
Query:     "medidas cautelares art. 319 CPP"
Documento: "...art. 319 do CÃ³digo de Processo Penal estabelece as 
            medidas cautelares diversas da prisÃ£o preventiva, como 
            comparecimento periÃ³dico, proibiÃ§Ã£o de frequentar lugares..."

Similaridade Alta porque:
âœ“ Termos exatos: "art. 319", "medidas cautelares"
âœ“ Contexto jurÃ­dico alinhado (CPP)
âœ“ Embeddings prÃ³ximos no espaÃ§o vetorial
âœ“ Coseno prÃ³ximo de 1.0
```

#### **MÃ©dia RelevÃ¢ncia (0.623)**
```
Query:     "medidas cautelares art. 319 CPP"
Documento: "...no CÃ³digo Penal Militar, as medidas cautelares seguem 
            regime especÃ­fico, conforme art. 290 do CPM..."

Similaridade MÃ©dia porque:
âœ“ Termo comum: "medidas cautelares"
âœ— Contexto diferente: militar vs. comum
âœ— Artigo diferente: 290 vs. 319
~ Embeddings relativamente prÃ³ximos
~ Coseno ~0.6
```

#### **Baixa RelevÃ¢ncia (0.412)**
```
Query:     "medidas cautelares art. 319 CPP"
Documento: "...crime de abandono material, previsto no art. 244 do 
            CÃ³digo Penal, nÃ£o comporta prisÃ£o preventiva..."

Similaridade Baixa porque:
~ Termos relacionados: "prisÃ£o", "CÃ³digo Penal"
âœ— Tema completamente diferente
âœ— Sem menÃ§Ã£o a medidas cautelares
âœ— Embeddings distantes
âœ— Coseno ~0.4
```

### MÃ©tricas Agregadas

O sistema tambÃ©m calcula mÃ©tricas agregadas para avaliar a qualidade da busca:

```typescript
// Calculado no frontend (index.vue)
const scores = searchResponse.results.map(r => r.score || 0)
const avgScore = scores.reduce((a, b) => a + b, 0) / scores.length
const topScore = Math.max(...scores)

// Exemplo:
// scores = [0.856, 0.782, 0.654, 0.589, 0.512]
// avgScore = 0.679  â†’ Qualidade MÃ‰DIA da busca
// topScore = 0.856  â†’ Melhor resultado
```

#### **AvaliaÃ§Ã£o de Qualidade da Busca**

| Avg Score | Top Score | AvaliaÃ§Ã£o | AÃ§Ã£o Recomendada |
|-----------|-----------|-----------|------------------|
| **â‰¥ 0.70** | **â‰¥ 0.85** | ğŸ¯ **Excelente** | Resposta confiÃ¡vel; alta cobertura |
| **0.50-0.69** | **0.70-0.84** | âš¡ **Boa** | Resposta Ãºtil; cobertura mÃ©dia |
| **0.30-0.49** | **0.50-0.69** | âš ï¸ **Fraca** | Verificar contexto; sugerir refinamento |
| **< 0.30** | **< 0.50** | âŒ **Inadequada** | Reformular query; documentos irrelevantes |

### Coverage Level (G2 Answer Composer)

O **G2** usa os scores implicitamente para determinar o nÃ­vel de cobertura:

```typescript
// LÃ³gica simplificada
if (avgScore >= 0.70 && citations.length >= 2) {
  coverage = 'high'      // ğŸ¯ Alta cobertura
} else if (avgScore >= 0.50 && citations.length >= 1) {
  coverage = 'medium'    // âš¡ MÃ©dia cobertura
} else if (avgScore >= 0.30) {
  coverage = 'low'       // âš ï¸ Baixa cobertura (gera sugestÃµes)
} else {
  coverage = 'none'      // âŒ Sem cobertura (rejeita resposta)
}
```

---

## âš¡ OtimizaÃ§Ãµes e Performance

### Ãndice FAISS

#### **IndexFlatIP vs. IndexIVFFlat**

```python
# Atual: IndexFlatIP (busca exaustiva)
base_index = faiss.IndexFlatIP(768)
# - Busca em todos os N documentos
# - Complexidade: O(N Ã— D) onde D=768
# - Preciso mas lento para N > 100k

# Alternativa: IndexIVFFlat (com clustering)
quantizer = faiss.IndexFlatIP(768)
index = faiss.IndexIVFFlat(quantizer, 768, n_clusters=100)
# - Divide em clusters (Voronoi cells)
# - Busca apenas em clusters prÃ³ximos
# - Complexidade: O(k Ã— D) onde k << N
# - Mais rÃ¡pido, pequena perda de precisÃ£o
```

#### **GPU Acceleration**

```python
# ConfigurÃ¡vel via environment variable
USE_FAISS_GPU = True
FAISS_GPU_DEVICE = 0

def maybe_to_gpu(index):
    if USE_FAISS_GPU and faiss.StandardGpuResources:
        res = faiss.StandardGpuResources()
        gpu_index = faiss.index_cpu_to_gpu(res, FAISS_GPU_DEVICE, index)
        # Speedup: ~10-50x dependendo do hardware
        return gpu_index
    return index
```

### Embedding Model

#### **Modelo Atual**
```
paraphrase-multilingual-MiniLM-L12-v2
- DimensÃµes: 768
- ParÃ¢metros: ~22M
- Velocidade: ~1000 sentenÃ§as/s (CPU)
- Linguagens: 50+ (incluindo portuguÃªs)
- Tamanho: ~420MB
```

#### **Alternativas**

| Modelo | DimensÃµes | Velocidade | Qualidade | Uso Recomendado |
|--------|-----------|------------|-----------|-----------------|
| `all-MiniLM-L6-v2` | 384 | âš¡âš¡âš¡ RÃ¡pido | â­â­â­ Bom | ProduÃ§Ã£o (inglÃªs) |
| `paraphrase-multilingual-MiniLM-L12-v2` | 768 | âš¡âš¡ MÃ©dio | â­â­â­â­ Ã“timo | **Atual** (multilingual) |
| `paraphrase-multilingual-mpnet-base-v2` | 768 | âš¡ Lento | â­â­â­â­â­ Excelente | Alta precisÃ£o |
| `LaBSE` | 768 | âš¡ Lento | â­â­â­â­â­ Excelente | Cross-lingual |

### Caching

```python
# ImplementaÃ§Ã£o futura
from functools import lru_cache

@lru_cache(maxsize=1000)
def encode_single_text_cached(text: str) -> np.ndarray:
    """Cacheia embeddings de queries frequentes."""
    return encoder.encode(text)

# BenefÃ­cios:
# - Queries repetidas: 0ms (cache hit)
# - Reduz carga no modelo
# - Melhora latÃªncia do G1
```

### Batch Processing

```python
# IndexaÃ§Ã£o em batch (mais eficiente)
def index(self, docs: List[Doc]) -> None:
    # Processa em batches de 32
    batch_size = 32
    for i in range(0, len(docs), batch_size):
        batch = docs[i:i+batch_size]
        texts = [doc.text for doc in batch]
        vectors = embeddings.encode_texts(texts)  # Batch encoding
        # ... adiciona ao Ã­ndice
```

### Performance Benchmarks

| OperaÃ§Ã£o | LatÃªncia | Throughput | Nota |
|----------|----------|------------|------|
| **Encode Query** (768D) | ~50ms | 20 queries/s | CPU (single thread) |
| **FAISS Search** (k=5, N=10k) | ~5ms | 200 searches/s | CPU (IndexFlatIP) |
| **FAISS Search** (k=5, N=10k) | ~0.5ms | 2000 searches/s | GPU (IndexFlatIP) |
| **API Roundtrip** | ~100-200ms | - | Inclui rede + serializaÃ§Ã£o |
| **Pipeline RAG Total** | ~1.5-2s | - | G1 + VDB + G2 |

---

## ğŸ”§ Troubleshooting

### Problemas Comuns

#### **1. Scores Muito Baixos (< 0.30)**

**Sintomas:**
```json
{
  "results": [
    { "id": "doc1", "score": 0.234 },
    { "id": "doc2", "score": 0.198 },
    { "id": "doc3", "score": 0.176 }
  ]
}
```

**Causas:**
- Query muito genÃ©rica ou ambÃ­gua
- Documentos no banco nÃ£o cobrem o tema
- Embeddings nÃ£o normalizados
- Modelo de embedding inadequado

**SoluÃ§Ãµes:**
```bash
# 1. Refinar query com G1 Query Builder
optimize = true

# 2. Adicionar mais documentos ao banco
make scrape-stf QUERY="art. 319"
make faiss-build

# 3. Verificar normalizaÃ§Ã£o dos embeddings
# embeddings.py: 
# encoder.encode(..., normalize_embeddings=True)

# 4. Testar modelo alternativo
EMBEDDING_MODEL="paraphrase-multilingual-mpnet-base-v2"
```

#### **2. Resultados Inconsistentes (VariaÃ§Ã£o de Scores)**

**Sintomas:**
- Mesma query retorna scores diferentes em buscas consecutivas
- Ordem dos resultados muda

**Causas:**
- Ãndice FAISS nÃ£o determinÃ­stico (IVF com `nprobe < nclusters`)
- Embeddings nÃ£o reproduzÃ­veis (seed nÃ£o fixado)

**SoluÃ§Ãµes:**
```python
# 1. Usar IndexFlat (determinÃ­stico)
base_index = faiss.IndexFlatIP(768)  # âœ“ Sempre mesmo resultado

# 2. Fixar seed do modelo
import torch
torch.manual_seed(42)
np.random.seed(42)

# 3. Aumentar nprobe (se usar IVF)
index.nprobe = 10  # Busca em mais clusters
```

#### **3. Erro "Store nÃ£o inicializado"**

**Sintomas:**
```
HTTPException 503: Store nÃ£o inicializado
```

**Causas:**
- FAISS index nÃ£o existe em `data/indexes/faiss/index.faiss`
- Metadados corrompidos

**SoluÃ§Ãµes:**
```bash
# 1. Verificar arquivos
ls -lh DBVECTOR/data/indexes/faiss/
# Deve ter: index.faiss + metadata.parquet

# 2. Recriar Ã­ndice
cd DBVECTOR
make faiss-build

# 3. Verificar logs da API
make api
# Procure por: "âœ… Ãndice carregado! N documentos"
```

#### **4. Metadados Ausentes (case_number, relator, source = null)**

**Sintomas:**
```json
{
  "id": "HC_187657",
  "case_number": null,
  "relator": null,
  "source": null
}
```

**Causas:**
- Campos nÃ£o estÃ£o no JSONL original
- Pipeline de build nÃ£o extrai metadados
- Ãndice criado antes da atualizaÃ§Ã£o

**SoluÃ§Ãµes:**
```bash
# 1. Verificar JSONL
head -n 1 stf_scraper/data/stf_jurisprudencia/art_244/*.jsonl | jq .
# Deve ter: case_number, relator, source

# 2. Re-indexar documentos
cd DBVECTOR
rm -rf data/indexes/faiss/*
make faiss-build  # Recria Ã­ndice com metadados

# 3. Validar na API
curl http://localhost:8000/search \
  -H "Content-Type: application/json" \
  -d '{"q": "art. 319", "k": 1}' | jq '.results[0]'
```

#### **5. LatÃªncia Alta (> 2.5s)**

**Sintomas:**
- Pipeline RAG demorando > 2.5s
- Timeout errors

**Causas:**
- Modelo de embedding lento (CPU)
- Ãndice FAISS muito grande sem otimizaÃ§Ã£o
- G1/G2 esperando resposta do GPT

**SoluÃ§Ãµes:**
```bash
# 1. Habilitar GPU FAISS
export USE_FAISS_GPU=true
export FAISS_GPU_DEVICE=0

# 2. Usar modelo mais rÃ¡pido
export EMBEDDING_MODEL="all-MiniLM-L6-v2"

# 3. Reduzir k (menos documentos)
k=3  # ao invÃ©s de 5

# 4. Otimizar prompts G1/G2
# - Reduzir max_tokens
# - Usar temperature=0 (mais rÃ¡pido)
```

### Debug Mode

#### **Habilitar Logging Detalhado**

```python
# DBVECTOR/src/config.py
LOGLEVEL = "DEBUG"

# Ou via environment variable
export LOGLEVEL=DEBUG
make api
```

#### **Inspecionar Embeddings**

```python
# Scripts de debug
from src import embeddings

# Testar embedding
query = "art. 319 CPP"
vector = embeddings.encode_single_text(query)
print(f"Shape: {vector.shape}")           # (768,)
print(f"Norm: {np.linalg.norm(vector)}")  # ~1.0 (normalizado)
print(f"Sample: {vector[:10]}")           # Primeiros 10 valores
```

#### **Validar Ãndice FAISS**

```python
from src.storage.factory import get_faiss_store

store = get_faiss_store()
print(f"Documentos: {store.get_doc_count()}")
print(f"Metadados: {len(store.metadata)}")

# Busca teste
query_vector = embeddings.encode_single_text("teste")
results = store.search(query_vector, k=1)
print(results[0].doc.id, results[0].score)
```

---

## ğŸ“š ReferÃªncias TÃ©cnicas

### Artigos e DocumentaÃ§Ã£o

1. **FAISS - Facebook AI Similarity Search**
   - Paper: [Efficient Similarity Search and Clustering of Dense Vectors](https://arxiv.org/abs/1702.08734)
   - Docs: https://faiss.ai/

2. **Sentence-Transformers**
   - Paper: [Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks](https://arxiv.org/abs/1908.10084)
   - Docs: https://www.sbert.net/

3. **Cosine Similarity & Inner Product**
   - [Understanding Cosine Similarity](https://en.wikipedia.org/wiki/Cosine_similarity)
   - [Dot Product vs Cosine Similarity](https://stackoverflow.com/questions/18424228/cosine-similarity-versus-dot-product-as-distance-metrics)

### Modelos de Embedding Recomendados

| Modelo | HuggingFace ID | Melhor para |
|--------|----------------|-------------|
| Atual (multilingual) | `sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2` | PortuguÃªs + multilingual |
| Alta qualidade PT/EN | `sentence-transformers/paraphrase-multilingual-mpnet-base-v2` | ProduÃ§Ã£o (precisÃ£o) |
| RÃ¡pido (apenas EN) | `sentence-transformers/all-MiniLM-L6-v2` | Prototipagem rÃ¡pida |
| Cross-lingual | `sentence-transformers/LaBSE` | Queries em mÃºltiplos idiomas |

### Ferramentas Ãšteis

- **FAISS Benchmarks**: https://github.com/facebookresearch/faiss/wiki/Indexing-1G-vectors
- **Embedding Explorer**: https://projector.tensorflow.org/
- **Vector DB Comparison**: https://benchmark.vectorview.ai/

---

## ğŸ“ Conceitos AvanÃ§ados

### Por que Produto Interno â‰ˆ Cosseno?

```python
# Vetores normalizados (norma L2 = 1)
||a|| = 1
||b|| = 1

# Produto interno:
dot(a, b) = Î£(a[i] Ã— b[i])

# Cosseno:
cos(Î¸) = dot(a, b) / (||a|| Ã— ||b||)
       = dot(a, b) / (1 Ã— 1)
       = dot(a, b)

# Portanto: Para vetores normalizados, dot = cos
```

### EspaÃ§o Vetorial de Embeddings

```
      a (query)
       â†‘ 
     Î¸ | \
       |  \ b (doc relevante, Î¸ pequeno, cos alto)
       |   \
       |    \
       |     \
â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â—â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ (eixo 1)
       |      \
       |       \ c (doc irrelevante, Î¸ grande, cos baixo)
       |        \
      â†“          â—
```

### Trade-offs de PrecisÃ£o vs. Velocidade

```
IndexFlat          â”€â”€â”€â”€â”€â”€â”€â”€â”€â—â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º 
(Atual)            Lento                  Preciso

IndexIVFFlat       â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â—â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º
                   MÃ©dio             Bom

IndexIVFPQ         â”€â”€â”€â”€â”€â”€â—â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º
(Comprimido)       RÃ¡pido        Aproximado
```

---

## ğŸ“Š MÃ©tricas de Monitoramento

### KPIs Recomendados

| MÃ©trica | Target | Alerta | CrÃ­tico |
|---------|--------|--------|---------|
| **Avg Score** | > 0.70 | < 0.50 | < 0.30 |
| **Top Score** | > 0.85 | < 0.70 | < 0.50 |
| **VDB Latency** | < 100ms | > 400ms | > 1000ms |
| **Documents Found** | â‰¥ 3 | < 3 | 0 |
| **Pipeline Total** | < 2s | > 2.5s | > 5s |

### RAG Ops Logger Integration

```typescript
// JÃ¡ implementado em useRagLogger.ts
const logEntry = {
  vdb: {
    avg_score: avgScore,  // â­ Monitora qualidade
    top_score: topScore,  // â­ Melhor resultado
    latency_ms: vdbLatency
  }
}

// ValidaÃ§Ãµes automÃ¡ticas
if (avgScore < 0.50) {
  status = 'WARN'  // âš ï¸ Alerta de qualidade baixa
}
```

---

## ğŸš€ PrÃ³ximos Passos

### Melhorias Planejadas

1. **Hybrid Search** (BM25 + Vector)
   ```python
   # Combinar busca lexical + semÃ¢ntica
   bm25_results = bm25_search(query, k=10)
   vector_results = faiss_search(query_vector, k=10)
   combined = rerank(bm25_results, vector_results, weights=[0.3, 0.7])
   ```

2. **Reranking com Cross-Encoder**
   ```python
   # Reordena top-k com modelo mais preciso
   initial = faiss_search(query_vector, k=20)
   reranked = cross_encoder.rank(query, [r.text for r in initial])
   final = reranked[:5]  # Top-5 rerankeados
   ```

3. **Clustering DinÃ¢mico**
   ```python
   # Agrupa documentos similares
   kmeans = faiss.Kmeans(768, n_clusters=50)
   kmeans.train(all_vectors)
   # Permite busca por cluster
   ```

4. **A/B Testing de Modelos**
   ```python
   # Compara modelos de embedding
   models = ['MiniLM', 'MPNet', 'LaBSE']
   for model in models:
       scores = evaluate(model, test_queries)
       print(f"{model}: avg_score={scores.mean()}")
   ```

---

**Projeto**: RAG-TCC  
**InstituiÃ§Ã£o**: LabTechUDF  
**Branch**: release/MVP  
**VersÃ£o**: 1.0.0  
**Autor**: Sistema RAG JurÃ­dico  
**Data**: 2025-01-05

---

## ğŸ“ Suporte

Para dÃºvidas ou problemas:

1. Verifique logs: `DBVECTOR/logs/` e console do navegador
2. Valide Ã­ndice: `make faiss-inspect`
3. Re-indexe se necessÃ¡rio: `make faiss-build`
4. Consulte documentaÃ§Ã£o RAG: `RAG_PIPELINE_FINAL.md`

ğŸ‰ **Sistema de RelevÃ¢ncia Vetorial Totalmente Documentado!**
