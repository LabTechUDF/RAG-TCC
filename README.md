# ğŸ›ï¸ STF Queue-Based Legal Content Scraper

A thread-safe web scraper for Brazilian Supreme Court (STF) legal decisions using **Scrapy**, **Playwright**, and **queue-based architecture**.

> **Status**: Production-ready STF scraper with concurrent queue processing for criminal law decisions.

## ğŸ—ï¸ Clean Architecture

### **Queue-Based Processing**
- **STFQueueManager**: Thread-safe queue management with fcntl file locking
- **Sequential Processing**: Safe, one-at-a-time query processing
- **Concurrent Processing**: Multi-worker concurrent processing with race condition protection

### **Core Components**
- `stf_jurisprudencia` - STF legal decisions spider (production-ready)
- `simple_query_spider` - Query URL generator (creates query_links.json)
- **Thread-safe pipelines**: Article-based JSON writer, validation, deduplication

## ğŸš€ How to Run

### **Requirements**
- Python 3.12+
- Poetry

### **Setup**
```bash
# Install dependencies  
poetry install

# Install browser
poetry run playwright install chromium
```

### **Queue-Based Commands**
```bash
# Go to scraper directory
cd stf_scraper

# Sequential processing (safe, single-threaded)
python manage.py sequential

# Concurrent processing (3 workers by default)
python manage.py concurrent --workers 3

# Show current queue status  
python manage.py status

# Clean up queue files
python manage.py cleanup

# Show browser for debugging
python manage.py sequential --show-browser
```

### **Development Helper**
```bash
# Use development script
./scripts/dev.sh sequential
./scripts/dev.sh concurrent  
./scripts/dev.sh status
```

### **Output**
Data organized by article number in `stf_scraper/data/stf_jurisprudencia/` with:
- **JSONL files**: Legal decisions by article (art_312/, art_323/, etc.)  
- **RTF files**: Original STF documents organized by article number
- **Thread-safe processing**: No duplicate queries or race conditions

## ğŸ“ Clean Structure
```
stf_scraper/
â”œâ”€â”€ manage.py                    # Clean queue-based CLI
â”œâ”€â”€ stf_queue_manager.py        # Thread-safe queue processing
â”œâ”€â”€ stf_scraper/
â”‚   â”œâ”€â”€ spiders/
â”‚   â”‚   â”œâ”€â”€ stf_jurisprudencia.py    # Main STF spider
â”‚   â”‚   â””â”€â”€ simple_query_spider.py   # Query generator
â”‚   â”œâ”€â”€ items.py                # Data structure definitions
â”‚   â”œâ”€â”€ pipelines.py           # Article-based processing
â”‚   â”œâ”€â”€ middlewares.py         # Simplified middlewares  
â”‚   â””â”€â”€ settings.py            # Playwright configuration
â”œâ”€â”€ data/                      # Organized scraped data
â””â”€â”€ configs/
    â””â”€â”€ queries.txt           # Source queries for processing
```

## ğŸ¯ Key Features

âœ… **Thread-Safe**: fcntl file locking prevents race conditions  
âœ… **Queue-Based**: Clean separation between queue management and spider execution  
âœ… **Concurrent**: Multi-worker processing with configurable worker count  
âœ… **Production-Ready**: No development modes, clean production focus  
âœ… **Organized Output**: Data organized by article number automatically  
âœ… **Resume Support**: Can resume interrupted processing from queue state
