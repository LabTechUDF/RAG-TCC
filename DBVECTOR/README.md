# üèõÔ∏è RAG Jur√≠dico

Sistema de **Retrieval-Augmented Generation (RAG)** para documentos jur√≠dicos com busca vetorial, desenvolvido para come√ßar com **FAISS** local e migrar facilmente para **OpenSearch** distribu√≠do.

## üéØ Vis√£o Geral

Este projeto oferece uma infraestrutura completa de RAG jur√≠dico com:

- **Busca vetorial** com embeddings sem√¢nticos (sentence-transformers)
- **Dois backends intercambi√°veis**: FAISS (local) e OpenSearch (distribu√≠do)
- **API REST** com FastAPI para integra√ß√£o
- **Testes abrangentes** com pytest (unit√°rios e integra√ß√£o)
- **Dados dummy** para valida√ß√£o imediata
- **Pipeline pronto** para plugar JSONs reais

## üèóÔ∏è Arquitetura

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   API FastAPI   ‚îÇ    ‚îÇ   Embeddings     ‚îÇ    ‚îÇ  Vector Store   ‚îÇ
‚îÇ  /search        ‚îÇ‚óÑ‚îÄ‚îÄ‚ñ∫‚îÇ sentence-transf. ‚îÇ‚óÑ‚îÄ‚îÄ‚ñ∫‚îÇ FAISS/OpenSrch ‚îÇ
‚îÇ  /health        ‚îÇ    ‚îÇ all-MiniLM-L6-v2 ‚îÇ    ‚îÇ cosine similarity‚îÇ
‚îÇ  /docs          ‚îÇ    ‚îÇ dim=384          ‚îÇ    ‚îÇ k-NN search     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üìã Pr√©-requisitos

### Op√ß√£o 1: Conda (Recomendado - com suporte GPU)
- **Conda** ou **Miniconda**
- **Driver NVIDIA** compat√≠vel com CUDA 12.1+ (para GPU)
- **Git**

### Op√ß√£o 2: Poetry (Alternativa - CPU apenas)
- **Python 3.10+**
- **Poetry** (gerenciador de depend√™ncias Python)
- **Git**

### Instala√ß√£o do Conda

```bash
# Windows
# Baixe Miniconda: https://docs.conda.io/en/latest/miniconda.html
# Execute o instalador e siga instru√ß√µes

# Linux
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
bash Miniconda3-latest-Linux-x86_64.sh

# Mac
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-MacOSX-x86_64.sh
bash Miniconda3-latest-MacOSX-x86_64.sh
```

### Verifica√ß√£o de GPU (opcional)

```bash
# Verificar driver NVIDIA
nvidia-smi

# Verificar vers√£o do driver (deve suportar CUDA 12.1+)
# Driver >= 530 para Linux
# Driver >= 531 para Windows
```

## üöÄ Instala√ß√£o R√°pida

### ‚ö° Atalho Windows (PowerShell)

**Setup autom√°tico:**
```powershell
# 1. Setup (detecta Conda/Poetry/pip e instala)
.\setup.ps1

# 2. Build do √≠ndice
.\build.ps1

# 3. Iniciar API
.\run-api.ps1

# 4. Testar (em outro terminal)
.\test-api.ps1
```

---

### Op√ß√£o 1: Conda (Recomendado)

#### Instala√ß√£o GPU (com acelera√ß√£o FAISS)

```bash
# Clone o reposit√≥rio
git clone <repo-url>
cd rag-juridico

# Cria ambiente Conda com suporte GPU
conda env create -f environment.gpu.yml

# Ativa o ambiente
conda activate rag-juridico

# Valida que GPU est√° dispon√≠vel
python -c "import faiss; print('FAISS GPU dispon√≠vel:', hasattr(faiss, 'StandardGpuResources'))"
python -c "import torch; print('CUDA dispon√≠vel:', torch.cuda.is_available())"

# Habilita GPU no runtime
# Windows PowerShell
$env:USE_FAISS_GPU="true"
$env:FAISS_GPU_DEVICE="0"

# Linux/Mac
export USE_FAISS_GPU=true
export FAISS_GPU_DEVICE=0

# Indexa documentos e inicia API
make faiss-build CONDA_ENV=rag-juridico
make api CONDA_ENV=rag-juridico
```

#### Instala√ß√£o CPU (sem GPU)

```bash
# Clone o reposit√≥rio
git clone <repo-url>
cd rag-juridico

# Cria ambiente Conda CPU
conda env create -f environment.cpu.yml

# Ativa o ambiente
conda activate rag-juridico-cpu

# Garante que GPU est√° desabilitado
# Windows PowerShell
$env:USE_FAISS_GPU="false"

# Linux/Mac
export USE_FAISS_GPU=false

# Indexa documentos e inicia API
make faiss-build CONDA_ENV=rag-juridico-cpu
make api CONDA_ENV=rag-juridico-cpu
```

### Op√ß√£o 2: Poetry (CPU apenas)

```bash
git clone <repo-url>
cd rag-juridico

# Instala com Poetry
poetry install

# Ativa ambiente virtual
poetry shell

# Fallback pip (se Poetry falhar no Windows)
python -m venv venv
# Windows: venv\Scripts\activate
# Linux/Mac: source venv/bin/activate
pip install -r requirements.txt
pip install -r requirements-dev.txt
```

> **üìù Nota Windows GPU**: Em Windows, recomenda-se usar **WSL2** com drivers CUDA para WSL para melhor compatibilidade GPU. Veja [DEPLOY_CONDA.md](DEPLOY_CONDA.md) para detalhes.

> **üìù Nota Poetry**: Poetry n√£o tem suporte nativo a FAISS GPU. Use Conda para habilitar GPU.

### 2. Configura√ß√£o

```bash
# Cria arquivo de configura√ß√£o (opcional - tem valores padr√£o)
cp .env.example .env

# Para habilitar GPU (apenas com ambiente Conda GPU)
echo "USE_FAISS_GPU=true" >> .env
echo "FAISS_GPU_DEVICE=0" >> .env

# Edite .env se necess√°rio (valores padr√£o funcionam para desenvolvimento)
```

### 3. Setup e Execu√ß√£o

```bash
# Com Conda (ajuste CONDA_ENV conforme seu ambiente)
make faiss-build CONDA_ENV=rag-juridico
make faiss-query CONDA_ENV=rag-juridico
make api CONDA_ENV=rag-juridico

# Com Poetry
make faiss-build
make faiss-query
make api
```

Pronto! Acesse http://localhost:8000/docs para documenta√ß√£o interativa.

### Verifica√ß√£o R√°pida (Sanity Check)

```bash
# Verifica configura√ß√£o GPU/CPU
make sanity

# Sa√≠da esperada:
# === Verifica√ß√£o de Sanidade ===
# GPU dispon√≠vel no FAISS?
# USE_FAISS_GPU = true (ou false)
# GPU symbols = True (ou False)
```

## ‚öôÔ∏è Configura√ß√£o (.env)

```bash
# Backend de busca (faiss|opensearch)
SEARCH_BACKEND=faiss

# Configura√ß√µes de Embedding
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
EMBEDDING_DIM=384
NORMALIZE_EMBEDDINGS=true

# FAISS (backend local)
FAISS_INDEX_PATH=data/indexes/faiss
FAISS_METADATA_PATH=data/indexes/faiss/metadata.parquet

# FAISS GPU (requer ambiente Conda GPU)
USE_FAISS_GPU=false         # true para habilitar GPU
FAISS_GPU_DEVICE=0          # ID da GPU (0, 1, 2, etc.)

# OpenSearch (backend distribu√≠do) 
OPENSEARCH_HOST=localhost
OPENSEARCH_PORT=9200
OPENSEARCH_INDEX=juridico-docs
OPENSEARCH_USE_SSL=false

# Query de teste para pipelines
QUERY=direitos fundamentais

# API
API_HOST=0.0.0.0
API_PORT=8000
```

## üîÑ Workflows

### Backend FAISS (Desenvolvimento Local)

```bash
# 1. Instala depend√™ncias
make install
# ou: poetry install

# 2. Indexa documentos dummy
make faiss-build

# 3. Testa busca via pipeline
make faiss-query

# 4. Inicia API
make api

# 5. Testa API
curl -X POST http://localhost:8000/search \
  -H "Content-Type: application/json" \
  -d '{"q": "direitos fundamentais", "k": 3}'
```

### Migra√ß√£o para OpenSearch

```bash
# 1. Inicia OpenSearch via Docker
make os-up

# 2. Aguarda inicializa√ß√£o (aguarde ~30s)
make os-build

# 3. Altera backend no .env
SEARCH_BACKEND=opensearch

# 4. Testa busca
make os-query

# 5. Reinicia API (automaticamente usa OpenSearch)
make api
```

### Comandos Makefile

| Comando | Descri√ß√£o |
|---------|-----------|
| `make env-gpu` | Cria ambiente Conda com suporte GPU |
| `make env-cpu` | Cria ambiente Conda CPU |
| `make install` | Instala depend√™ncias com Poetry |
| `make shell` | Ativa ambiente virtual Poetry |
| `make format` | Formata c√≥digo (black + isort) |
| `make lint` | Verifica formata√ß√£o e estilo |
| `make data-merge` | Consolida dados JSON/JSONL |
| `make data-validate` | Valida qualidade dos dados |
| `make faiss-build` | Indexa docs no FAISS |
| `make faiss-query` | Busca no FAISS |
| `make os-up` | Inicia OpenSearch (Docker) |
| `make os-down` | Para OpenSearch |
| `make os-build` | Indexa docs no OpenSearch |
| `make os-query` | Busca no OpenSearch |
| `make api` | Inicia API FastAPI |
| `make test` | Executa todos os testes |
| `make test-cov` | Testes com cobertura |
| `make bench` | Executa benchmarks |
| `make bench-compare` | Compara com baseline |
| `make eval` | Avalia recupera√ß√£o (FAISS) |
| `make eval-opensearch` | Avalia recupera√ß√£o (OpenSearch) |
| `make inspect-emb` | Inspeciona embeddings |
| `make quality` | Workflow completo de qualidade |
| `make sanity` | Verifica GPU/CPU e configura√ß√£o |
| `make demo` | Script de demonstra√ß√£o |

**Nota:** Comandos Makefile usam `conda run` por padr√£o. Especifique o ambiente:
```bash
# Exemplo com ambiente GPU
make test CONDA_ENV=rag-juridico

# Exemplo com ambiente CPU
make test CONDA_ENV=rag-juridico-cpu
```

## üß™ Testes

### Executar Testes

```bash
# Todos os testes
make test
# ou: poetry run pytest tests/ -v

# Com cobertura
make test-cov
# ou: poetry run pytest tests/ --cov=src --cov-report=html

# Apenas FAISS
poetry run pytest tests/test_faiss_store.py -v

# Apenas API
poetry run pytest tests/test_api_faiss.py -v

# OpenSearch (requer servi√ßo rodando)
make os-up
poetry run pytest tests/test_opensearch_store.py -v
```

### Estrutura de Testes

- **test_embeddings.py**: Testa gera√ß√£o de embeddings
- **test_faiss_store.py**: Testa store FAISS
- **test_opensearch_store.py**: Testa store OpenSearch (condicional)
- **test_api_faiss.py**: Testa API de ponta a ponta

Testes de OpenSearch s√£o **automaticamente ignorados** se o servi√ßo n√£o estiver dispon√≠vel.

## üìä Dados Dummy

O projeto inclui 5 documentos jur√≠dicos dummy para valida√ß√£o:

1. **Constitui√ß√£o Federal Art. 5¬∫** - Direitos fundamentais
2. **STF HC 123.456** - Habeas corpus e liberdade
3. **C√≥digo Civil Art. 197** - Prescri√ß√£o entre c√¥njuges  
4. **C√≥digo Civil Art. 178** - Decad√™ncia de neg√≥cios jur√≠dicos
5. **STJ REsp 987.654** - Responsabilidade do consumidor

## üìà M√©tricas & Qualidade

O projeto inclui um **pacote completo de valida√ß√£o, testes, benchmarks, avalia√ß√£o e monitoramento** para garantir qualidade e performance.

### 1. Valida√ß√£o de Dados

Valida qualidade dos dados antes da indexa√ß√£o, medindo:
- % documentos com campos ausentes
- % documentos com texto muito curto
- % documentos com tokens HTML/residuais
- IDs duplicados
- % total de problemas

**Uso:**
```bash
# Via Makefile
make data-validate

# Ou diretamente
poetry run python -m src.tools.validate_data \
  --input data/merged_clean.jsonl \
  --min-chars 200 \
  --max-bad-pct 10 \
  --report reports/validation/report.json
```

**Exemplo de relat√≥rio:**
```json
{
  "total": 1000,
  "missing_fields_pct": 1.2,
  "too_short_pct": 3.4,
  "bad_tokens_pct": 5.0,
  "dupe_ids": 12,
  "bad_overall_pct": 8.1,
  "ok_to_proceed": true
}
```

**Gating:** Falha automaticamente se `bad_overall_pct > max-bad-pct` (default: 10%).

### 2. Testes Unit√°rios e Funcionais

Al√©m dos testes existentes, agora incluem:

```bash
# Todos os testes
poetry run pytest -v

# Testes sem OpenSearch (skip autom√°tico se n√£o dispon√≠vel)
poetry run pytest -m "not opensearch" -v

# Com cobertura
poetry run pytest --cov=src --cov-report=html
```

**Novos testes:**
- `test_api_search.py` - Contrato da API /search
- `test_dedupe_and_ids.py` - Deduplica√ß√£o e mapeamento de IDs
- `test_io_pipelines.py` - Ingest√£o e round-trip de JSON/JSONL
- `test_validate_data.py` - Valida√ß√£o de dados

### 3. Benchmarks de Performance

Usa `pytest-benchmark` para medir lat√™ncia e throughput:

**Lat√™ncia de queries:**
```bash
# Executar e salvar baseline
make bench
# ou: poetry run pytest tests/bench --benchmark-save=baseline

# Comparar com baseline
make bench-compare
# ou: poetry run pytest tests/bench --benchmark-compare
```

**M√©tricas:**
- **P95 de lat√™ncia** de `/search` (SLO: 200ms)
- **Tempo de build** de √≠ndice FAISS (SLO: 60s)
- **Throughput** de queries (m√≠n: 10 QPS)

**Exemplo de sa√≠da:**
```
üìä Lat√™ncia k=5:
   Mean: 45.23ms
   Median: 42.10ms
   P95 (approx): 68.45ms
   SLO: 200ms
‚úÖ SLO atendido
```

### 4. Avalia√ß√£o de Recupera√ß√£o

Mede qualidade da recupera√ß√£o usando dataset de Q&A com ground-truth:

```bash
# FAISS
make eval
# ou: poetry run python -m src.eval.retrieval_eval \
#   --qa data/eval/qa_dev.jsonl \
#   --k 5 \
#   --backend faiss \
#   --report reports/eval/retrieval_metrics.json \
#   --csv reports/eval/retrieval_metrics.csv

# OpenSearch
make eval-opensearch
```

**M√©tricas calculadas:**
- **Precision@K**: % de docs relevantes nos top-K
- **Recall@K**: % de docs relevantes recuperados
- **MRR (Mean Reciprocal Rank)**: Posi√ß√£o do primeiro doc relevante
- **nDCG@K**: Normalized Discounted Cumulative Gain

**Thresholds (configur√°veis via .env):**
- `MIN_P5=0.55` - Precision@5 m√≠nima
- `MIN_NDCG5=0.70` - nDCG@5 m√≠nimo

**Exemplo de relat√≥rio:**
```
üìà Resultados:
   Queries avaliadas: 20
   K: 5

   Precision@5: 0.6200
   Recall@5: 0.7800
   MRR: 0.8500
   nDCG@5: 0.7650

‚úÖ Avalia√ß√£o aprovada!
```

**Dataset de avalia√ß√£o:**
- `data/eval/qa_dev.jsonl` - 20 pares de pergunta/docs relevantes
- Cobre casos dos documentos dummy

### 5. Inspe√ß√£o de Embeddings

Detecta problemas nos vetores (NaNs, colapso, duplicatas):

```bash
# Gera embeddings e inspeciona
make inspect-emb
# ou: poetry run python -m src.eval.inspect_embeddings \
#   --input data/merged_clean.jsonl \
#   --mode generate \
#   --report reports/inspect/embeddings_summary.json
```

**Detec√ß√µes:**
- **NaN/Inf**: Vetores inv√°lidos
- **Colapso**: Vetores com norma L2 muito baixa (< 0.1)
- **Near-duplicates**: Pares com similaridade cosine ‚â• 0.995

**Exemplo de relat√≥rio:**
```
üìà Resultados:
   Vetores: 1000
   Dimens√£o: 384 (esperado: 384)

üî¨ Valida√ß√£o:
   Dimens√£o OK: True
   NaN: 0 ‚úÖ
   Inf: 0 ‚úÖ

üìè Norma L2:
   M√©dia: 0.9845
   P5: 0.9512
   P95: 1.0234
   Colapsados: 0 (0.00%)

üîÅ Near-Duplicates:
   Count: 8
   %: 0.0800%

‚úÖ Inspe√ß√£o aprovada!
```

**Gating:** Falha se NaNs > 0 ou near-duplicates > `NEAR_DUPES_MAX_PCT` (default: 1%).

### 6. Workflow Completo de Qualidade

Execute todas as verifica√ß√µes de uma vez:

```bash
make quality
# Executa: data-validate + bench + eval + inspect-emb
```

### 7. Configura√ß√£o de Thresholds

Adicione ao `.env`:

```bash
# Valida√ß√£o de Dados
MIN_CHARS=200
VALIDATION_MAX_BAD_PCT=10

# SLOs e Benchmarks
SLO_P95_MS=200
MAX_BUILD_TIME_S=60

# Thresholds de Avalia√ß√£o de Recupera√ß√£o
MIN_P5=0.55
MIN_NDCG5=0.70

# Inspe√ß√£o de Embeddings
NEAR_DUPES_MAX_PCT=1
```

### 8. CI/CD com GitHub Actions

O workflow `.github/workflows/ci.yml` executa automaticamente:

**Jobs:**
1. **validate_data** - Valida qualidade dos dados
2. **tests** - Executa testes unit√°rios e funcionais
3. **bench** - Mede performance e compara com baseline
4. **eval** - Avalia m√©tricas de recupera√ß√£o
5. **lint** - Verifica formata√ß√£o do c√≥digo

**Triggers:**
- Push em `main` e branches de desenvolvimento
- Pull requests
- Diariamente √†s 6h UTC (cron)

**Artifacts:**
- Relat√≥rios de valida√ß√£o
- Resultados de benchmarks
- M√©tricas de avalia√ß√£o
- Cobertura de c√≥digo

**Exemplo de uso:**
```bash
# Localmente antes de commit
make quality
poetry run pytest -v

# CI executa automaticamente no push
git push origin feature/nova-funcionalidade
```

### 9. Estrutura de Relat√≥rios

```
reports/
‚îú‚îÄ‚îÄ validation/
‚îÇ   ‚îî‚îÄ‚îÄ report.json          # M√©tricas de qualidade de dados
‚îú‚îÄ‚îÄ eval/
‚îÇ   ‚îú‚îÄ‚îÄ retrieval_metrics.json    # M√©tricas agregadas
‚îÇ   ‚îî‚îÄ‚îÄ retrieval_metrics.csv     # Detalhes por query
‚îî‚îÄ‚îÄ inspect/
    ‚îî‚îÄ‚îÄ embeddings_summary.json   # Sa√∫de dos embeddings
```

### 10. Comandos Makefile de Qualidade

| Comando | Descri√ß√£o |
|---------|-----------|
| `make data-validate` | Valida qualidade dos dados |
| `make bench` | Executa benchmarks e salva baseline |
| `make bench-compare` | Compara com baseline anterior |
| `make eval` | Avalia m√©tricas de recupera√ß√£o (FAISS) |
| `make eval-opensearch` | Avalia m√©tricas (OpenSearch) |
| `make inspect-emb` | Inspeciona embeddings |
| `make quality` | Executa todos os checks de qualidade |

### üßπ Consolidar dados para indexa√ß√£o

Para preparar dados reais para indexa√ß√£o, o projeto inclui um utilit√°rio que consolida arquivos `.json` e `.jsonl` recursivamente, remove registros com `cluster_name == "unknown"` e gera um √∫nico arquivo JSONL limpo:

```bash
# Uso b√°sico (via Makefile)
make data-merge

# Ou diretamente com Poetry
poetry run python -m src.tools.tratamento_dados \
  --input data \
  --output data/merged_clean.jsonl \
  --dedupe-by id

# Op√ß√µes avan√ßadas
poetry run python -m src.tools.tratamento_dados \
  --input data/raw \
  --output data/processed/clean.jsonl \
  --dedupe-by hash \
  --ignore-hidden \
  --quiet
```

**Par√¢metros dispon√≠veis:**
- `--input, -i`: Diret√≥rio raiz para varredura (default: `data`)
- `--output, -o`: Arquivo de sa√≠da JSONL (default: `data/merged_clean.jsonl`)
- `--dedupe-by`: Estrat√©gia de deduplica√ß√£o - `id`, `hash`, ou `none` (default: `id`)
- `--ignore-hidden`: Ignora arquivos e pastas iniciados por `.` (default: ativo)
- `--extensions`: Extens√µes de arquivo, separadas por v√≠rgula (default: `.json,.jsonl`)
- `--quiet`: Reduz verbosidade (apenas avisos e erros)
- `--stats`: Imprime estat√≠sticas finais em JSON

**O que o utilit√°rio faz:**
- ‚úÖ Varre recursivamente o diret√≥rio de entrada
- ‚úÖ Processa arquivos `.json` (lista ou objeto √∫nico) e `.jsonl` (linha a linha)
- ‚úÖ Filtra registros onde `cluster_name` seja `"unknown"` (case-insensitive)
- ‚úÖ Remove duplicados baseado em `id` ou `hash` (configurable)
- ‚úÖ Valida que registros sejam objetos JSON v√°lidos
- ‚úÖ Gera sa√≠da JSONL pronta para indexa√ß√£o
- ‚úÖ Logging detalhado com estat√≠sticas de processamento

## üîß Como Plugar JSONs Reais

### 1. Criar Normalizador

```python
# src/data_loader.py
from src.schema import Doc
import json

def load_from_json(json_path: str) -> List[Doc]:
    """Carrega documentos de arquivo JSON real."""
    with open(json_path) as f:
        data = json.load(f)
    
    docs = []
    for item in data:
        # Adapte campos conforme seu JSON
        doc = Doc(
            id=item["id"],
            text=item["texto_completo"],  # Campo principal para busca
            title=item.get("titulo"),
            court=item.get("tribunal"),
            code=item.get("codigo"),
            article=item.get("artigo"), 
            date=item.get("data"),
            meta=item.get("metadados", {})
        )
        docs.append(doc)
    
    return docs
```

### 2. Atualizar Pipeline

```python
# src/pipelines/build_real_data.py
from src.data_loader import load_from_json
from src.storage.factory import get_store

def main():
    # Carrega dados reais
    docs = load_from_json("data/documentos_juridicos.json")
    
    # Indexa no backend configurado
    store = get_store()
    store.index(docs)
```

### 3. Campo Text Can√¥nico

Para documentos complexos, concatene campos relevantes:

```python
def create_canonical_text(item: dict) -> str:
    """Cria texto can√¥nico para busca."""
    parts = []
    
    if item.get("titulo"):
        parts.append(item["titulo"])
    
    if item.get("ementa"):
        parts.append(item["ementa"])
        
    if item.get("texto_completo"):
        parts.append(item["texto_completo"])
    
    return " ".join(parts)
```

## üöÄ Pr√≥ximos Passos

### Funcionalidades Avan√ßadas

1. **Busca H√≠brida** (BM25 + kNN)
   - Implementar no OpenSearch
   - Combinar busca lexical e sem√¢ntica

2. **Filtros Estruturados**
   - Por tribunal, data, tipo de documento
   - Filtros combinados com busca vetorial

3. **Avalia√ß√£o de Qualidade**
   - M√©tricas nDCG@k, MRR
   - Dataset de relev√¢ncia manual

4. **Otimiza√ß√µes**
   - Cache de embeddings
   - Quantiza√ß√£o de vetores
   - Sharding para grandes volumes

### Ambiente de Produ√ß√£o

1. **Seguran√ßa OpenSearch**
   ```yaml
   # docker-compose.prod.yml
   services:
     opensearch:
       environment:
         - plugins.security.disabled=false
         - OPENSEARCH_INITIAL_ADMIN_PASSWORD=<senha-forte>
   ```

2. **Monitoramento**
   - Logs estruturados
   - M√©tricas de lat√™ncia
   - Health checks

3. **Escalabilidade**
   - Load balancer para API
   - Cluster OpenSearch multi-n√≥
   - Cache Redis para queries frequentes

## üìö API Reference

### POST /search

Busca documentos por similaridade sem√¢ntica.

**Request:**
```json
{
  "q": "direitos fundamentais constitucionais",
  "k": 5
}
```

**Response:**
```json
{
  "query": "direitos fundamentais constitucionais",
  "total": 3,
  "backend": "faiss",
  "results": [
    {
      "id": "cf88_art5",
      "title": "Constitui√ß√£o Federal - Art. 5¬∫",
      "text": "Todos s√£o iguais perante a lei...",
      "court": "Constitui√ß√£o Federal",
      "code": "CF/88",
      "article": "5¬∫",
      "date": "1988-10-05",
      "score": 0.8956
    }
  ]
}
```

### Endpoints Auxiliares

- `GET /` - Informa√ß√µes da API
- `GET /health` - Health check
- `GET /docs` - Documenta√ß√£o Swagger

## ÔøΩ Gerenciamento de Depend√™ncias com Poetry

Este projeto usa **Poetry** para gerenciamento moderno de depend√™ncias e ambientes virtuais.

### Comandos Poetry √öteis

```bash
# Instalar depend√™ncias
poetry install

# Ativar ambiente virtual
poetry shell

# Executar comandos no ambiente virtual
poetry run python script.py
poetry run pytest
poetry run uvicorn src.api.main:app

# Adicionar nova depend√™ncia
poetry add requests
poetry add --group dev black  # depend√™ncia de desenvolvimento

# Atualizar depend√™ncias
poetry update

# Mostrar depend√™ncias
poetry show
poetry show --tree

# Informa√ß√µes do ambiente
poetry env info
poetry env list

# Exportar requirements.txt (se necess√°rio)
poetry export -f requirements.txt --output requirements.txt
poetry export --with dev -f requirements.txt --output requirements-dev.txt
```

### Vantagens do Poetry

- **Resolu√ß√£o autom√°tica** de conflitos de depend√™ncias
- **Lock file** (`poetry.lock`) para builds reproduz√≠veis  
- **Ambiente virtual** gerenciado automaticamente
- **Build e publica√ß√£o** de pacotes Python
- **Configura√ß√£o unificada** em `pyproject.toml`

## üêõ Troubleshooting

### FAISS

**Erro: "No module named 'faiss'"**
```bash
# Com Conda
conda activate rag-juridico
conda list | grep faiss

# Com Poetry
poetry add faiss-cpu
```

**Erro: FAISS GPU n√£o funciona**
```bash
# 1. Verificar s√≠mbolos GPU
python -c "import faiss; print('GPU:', hasattr(faiss, 'StandardGpuResources'))"

# 2. Se False, verificar instala√ß√£o
conda list | grep faiss
# Deve mostrar faiss-gpu (n√£o faiss-cpu)

# 3. Verificar CUDA
python -c "import torch; print('CUDA:', torch.version.cuda)"
# Deve mostrar 12.1

# 4. Verificar driver
nvidia-smi
# Driver deve ser >= 530 (Linux) ou >= 531 (Windows)

# 5. Reinstalar ambiente
conda env remove -n rag-juridico
make env-gpu
```

**Erro: "Index file not found"**
```bash
make faiss-build  # Reconstr√≥i √≠ndice
```

**Erro: Mem√≥ria GPU esgotada**
```bash
# 1. Verificar uso
nvidia-smi

# 2. Liberar mem√≥ria
python -c "import torch; torch.cuda.empty_cache()"

# 3. Usar CPU como fallback
# Windows PowerShell
$env:USE_FAISS_GPU="false"

# Linux/Mac
export USE_FAISS_GPU=false

make faiss-build
```

### Conda

**Erro: "conda: command not found"**
```bash
# Reinstale Miniconda
# https://docs.conda.io/en/latest/miniconda.html
```

**Erro: Ambiente Conda muito lento**
```bash
# Use mamba (mais r√°pido)
conda install -n base -c conda-forge mamba
mamba env create -f environment.gpu.yml
```

**Conflito de depend√™ncias**
```bash
# Limpa cache e recria
conda clean --all
conda env remove -n rag-juridico
make env-gpu
```

### Windows GPU

**GPU n√£o funciona no Windows nativo**

Para GPU no Windows, recomenda-se **WSL2**:

```powershell
# 1. Instalar WSL2
wsl --install

# 2. Instalar driver CUDA para WSL
# Baixe de: https://developer.nvidia.com/cuda/wsl

# 3. No WSL, verificar
nvidia-smi

# 4. Instalar Miniconda no WSL
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
bash Miniconda3-latest-Linux-x86_64.sh

# 5. Criar ambiente GPU no WSL
conda env create -f environment.gpu.yml
```

Veja [DEPLOY_CONDA.md](DEPLOY_CONDA.md) para guia completo WSL2.

### OpenSearch

**Erro: "Connection refused"**
```bash
make os-up  # Inicia container
docker logs opensearch-rag  # Verifica logs
```

**Erro: "Index not found"**
```bash
make os-build  # Cria √≠ndice e indexa docs
```

### API

**Erro 503: "Store n√£o inicializado"**
- Verifique se backend est√° configurado
- Execute pipeline de build antes da API

**Erro 404: "Nenhum documento indexado"**
```bash
# Para FAISS
make faiss-build

# Para OpenSearch  
make os-build
```

## ü§î Por que come√ßar com FAISS e depois migrar para OpenSearch?

### FAISS: Simplicidade e Valida√ß√£o Inicial
FAISS (Facebook AI Similarity Search) √© uma biblioteca leve e eficiente para busca vetorial local. Ele √© ideal para a fase inicial do projeto porque:
- **Valida√ß√£o r√°pida**: Permite testar embeddings, pipelines e a API sem necessidade de infraestrutura complexa.
- **Desempenho local**: Funciona diretamente em mem√≥ria, com alta performance para conjuntos de dados pequenos ou m√©dios.
- **Simplicidade**: N√£o requer configura√ß√£o de servidores ou depend√™ncias externas, tornando o desenvolvimento mais √°gil.

### OpenSearch: Escalabilidade e Produ√ß√£o
OpenSearch √© uma solu√ß√£o distribu√≠da e escal√°vel, ideal para ambientes de produ√ß√£o. Ele √© recomendado quando:
- **Escalabilidade**: Voc√™ precisa lidar com milh√µes de documentos ou m√∫ltiplos usu√°rios simult√¢neos.
- **Distribui√ß√£o**: Suporta clusters distribu√≠dos, com r√©plicas e alta disponibilidade.
- **Funcionalidades avan√ßadas**: Oferece suporte a filtros, busca h√≠brida (BM25 + kNN), e integra√ß√£o com dashboards para an√°lise.

### Estrat√©gia Incremental
1. **FAISS primeiro**: Comece validando o sistema com dados dummy e FAISS. Isso garante que os embeddings, pipelines e a API est√£o funcionando corretamente.
2. **Migre para OpenSearch**: Quando estiver pronto para escalar ou integrar dados reais, altere o backend para OpenSearch no `.env` e siga os passos de configura√ß√£o.

Essa abordagem incremental reduz a complexidade inicial, permitindo que voc√™ foque no desenvolvimento do MVP antes de lidar com a infraestrutura distribu√≠da. Assim, voc√™ valida o sistema localmente com FAISS e, quando necess√°rio, escala para OpenSearch sem refazer o trabalho.

## üìÑ Licen√ßa

MIT License - veja LICENSE para detalhes.

## ü§ù Contribui√ß√£o

1. Fork o projeto
2. Crie branch para feature (`git checkout -b feature/nova-funcionalidade`)
3. Commit mudan√ßas (`git commit -m 'Adiciona nova funcionalidade'`)
4. Push para branch (`git push origin feature/nova-funcionalidade`)
5. Abra Pull Request

---

## üìû Suporte

Para d√∫vidas ou problemas:

1. Verifique a se√ß√£o [Troubleshooting](#-troubleshooting)
2. Consulte logs da aplica√ß√£o
3. Execute testes para diagn√≥stico: `make test`
4. Abra issue no reposit√≥rio

**Desenvolvido para acelerar projetos de RAG jur√≠dico** üöÄ