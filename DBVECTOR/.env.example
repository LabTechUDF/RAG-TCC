# Backend de busca vetorial (faiss|opensearch)
SEARCH_BACKEND=faiss

# Configurações de Embedding
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
EMBEDDING_DIM=384
NORMALIZE_EMBEDDINGS=true

# Configurações FAISS
FAISS_INDEX_PATH=data/indexes/faiss
FAISS_METADATA_PATH=data/indexes/faiss/metadata.parquet

# Configurações FAISS GPU (requer ambiente Conda GPU)
USE_FAISS_GPU=false
FAISS_GPU_DEVICE=0

# Configurações OpenSearch
OPENSEARCH_HOST=localhost
OPENSEARCH_PORT=9200
OPENSEARCH_INDEX=juridico-docs
OPENSEARCH_USERNAME=
OPENSEARCH_PASSWORD=
OPENSEARCH_USE_SSL=false

# Query de teste para pipelines
QUERY=direitos fundamentais

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000

# Validação de Dados
MIN_CHARS=200
VALIDATION_MAX_BAD_PCT=10

# SLOs e Benchmarks
SLO_P95_MS=200
MAX_BUILD_TIME_S=60

# Thresholds de Avaliação de Recuperação
MIN_P5=0.55
MIN_NDCG5=0.70

# Inspeção de Embeddings
NEAR_DUPES_MAX_PCT=1

# ==============================================================================
# CONFIGURAÇÕES LANGCHAIN RAG
# ==============================================================================

# API Key da OpenAI para LLM (query optimization e geração de respostas)
# Obtenha sua chave em: https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here

# Configurações de Chunking
# CHUNK_SIZE: Tamanho máximo de cada chunk em caracteres (padrão: 1000)
CHUNK_SIZE=1000

# CHUNK_OVERLAP: Sobreposição entre chunks em caracteres (padrão: 200)
CHUNK_OVERLAP=200